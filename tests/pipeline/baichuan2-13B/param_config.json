 {
    "test_baichuan2_mmlu_evaluate": [
        {
            "param": {
                "task-data-path": "/data/eval_data/mmlu/data/test",
                "task": "mmlu",
                "tensor-model-parallel-size": 8,
                "pipeline-model-parallel-size": 1,
                "num-layers": 40,
                "hidden-size": 5120,
                "ffn-hidden-size": 13696,
                "num-attention-heads": 40,
                "seq-length": 4096,
                "max-new-tokens": 1,
                "max-position-embeddings": 4096,
                "make-vocab-size-divisible-by": 32,
                "micro-batch-size": 1,
                "normalization": "RMSNorm",
                "position-embedding-type": "alibi",
                "swiglu": null,
                "tokenizer-not-use-fast": null,
                "untie-embeddings-and-output-weights": null,
                "disable-bias-linear": null,
                "fp16": null,
                "no-load-rng": null,
                "no-load-optim": null,
                "load": "/data/pipe/baichuan2-13b-tp8pp1-legacy-base",
                "tokenizer-type": "PretrainedFromHF",
                "tokenizer-name-or-path": "/data/baichuan2-13B-hf/",
                "use-deter-comp": null
            }
        }
    ],

    "test_baichuan2_greedy_search": [
        {
            "param": {
                "tensor-model-parallel-size": 8,
                "pipeline-model-parallel-size": 1,
                "sequence-parallel": null,
                "num-layers": 40,
                "hidden-size": 5120,
                "ffn-hidden-size": 13696,
                "num-attention-heads": 40,
                "seq-length": 4096,
                "max-position-embeddings": 4096,
                "make-vocab-size-divisible-by": 32,
                "normalization": "RMSNorm",
                "position-embedding-type": "alibi",
                "load": "/data/pipe/baichuan2-13b-tp8pp1-legacy-base",
                "tokenizer-type": "PretrainedFromHF",
                "tokenizer-name-or-path": "/data/baichuan2-13B-hf/",
                "disable-bias-linear": null,
                "use-fused-rmsnorm": null,
                "swiglu": null,
                "attention-softmax-in-fp32": null,
                "untie-embeddings-and-output-weights": null,
                "no-masked-softmax-fusion": null,
                "no-load-optim": null,
                "no-load-rng": null,
                "bf16": null,
                "task": "greedy",
                "max-new-tokens": 30,
                "micro-batch-size": 4,
                "global-batch-size": 16,
                "use-deter-comp": null
            }
        }
    ],

    "test_preprocess_pretrain_data": [
        {
            "param": {
                "input": "/data/train-00000-of-00001-a09b74b3ef9c3b56.parquet",
                "tokenizer-type": "PretrainedFromHF",
                "tokenizer-name-or-path": "/data/baichuan2-13B-hf/"
            },
            "prefix": "alpaca"
        }
    ]
}